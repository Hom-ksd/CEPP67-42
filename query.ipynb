{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import re\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"chroma\"\n",
    "url = 'https://7jb5pn2q0l4lf2-8000.proxy.runpod.net/v1/completions'\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer and explain the question with Thai language based only on the following context:\n",
    "โดยทุจริต = เพื่อแสวงหาประโยชน์ที่มิควรได้โดยชอบด้วยกฎหมายสําหรับตนเองหรือผู้อื่น\n",
    "ทางสาธารณะ = ทางบกหรือทางน้ําสําหรับประชาชนใช้ในการจราจร และให้หมายความรวมถึงทางรถไฟและทางรถรางที่มีรถเดิน สําหรับประชาชนโดยสารด้วย\n",
    "สาธารณสถาน = สถานที่ใด ๆ ซึ่งประชาชนมีความชอบธรรมที่จะเข้าไปได้\n",
    "เคหสถาน = ที่ซึ่งใช้เป็นที่อยู่อาศัย เช่น เรือน โรง เรือ หรือแพซึ่งคนอยู่อาศัยและให้หมายความรวมถึงบริเวณของที่ซึ่งใช้เป็นที่อยู่อาศัยนั้นด้วย จะมีรั้วล้อมหรือไม่ก็ตาม\n",
    "อาวุธ = หมายความรวมถึงสิ่งซึ่งไม่เป็นอาวุธโดยสภาพ แต่ซึ่งได้ใช้หรือเจตนาจะใช้ประทุษร้ายร่างกายถึงอันตรายสาหัสอย่างอาวุธ\n",
    "ใช้กําลังประทุษร้าย = ทําการประทุษร้ายแก่กายหรือจิตใจของบุคคล ไม่ว่าจะทําด้วยใช้แรงกายภาพหรือด้วยวิธีอื่นใด และให้หมายความรวมถึงการกระทําใด ๆ ซึ่งเป็นเหตุให้บุคคลหนึ่งบุคคลใดอยู่ในภาวะที่ไม่สามารถขัดขืนได้ \n",
    "ไม่ว่าจะโดยใช้ยาทําให้มึนเมา สะกดจิต หรือใช้วิธีอื่นใดอันคล้ายคลึงกัน\n",
    "เอกสาร = กระดาษหรือวัตถุอื่นใดซึ่งได้ทําให้ปรากฏความหมายด้วยตัวอักษร ตัวเลข ผัง หรือแผนแบบอย่างอื่น จะเป็นโดยวิธีพิมพ์ ถ่ายภาพ หรือวิธีอื่นอันเป็นหลักฐานแห่งความหมายนั้น\n",
    "เอกสารราชการ = เอกสารซึ่งเจ้าพนักงานได้ทําขึ้นหรือรับรองในหน้าที่ และให้หมายความรวมถึงสําเนาเอกสารนั้น ๆ ที่เจ้าพนักงานได้รับรองในหน้าที่ด้วย\n",
    "เอกสารสิทธิ = เอกสารที่เป็นหลักฐานแห่งการก่อ เปลี่ยนแปลงโอน สงวนหรือระงับซึ่งสิทธิ\n",
    "ลายมือชื่อ = หมายความรวมถึงลายพิมพ์นิ้วมือและเครื่องหมายซึ่งบุคคลลงไว้แทนลายมือชื่อของตน\n",
    "กลางคืน = เวลาระหว่างพระอาทิตย์ตกและพระอาทิตย์ขึ้น\n",
    "คุมขัง = คุมตัว ควบคุม ขัง กักขังหรือจําคุก\n",
    "ค่าไถ่ = ทรัพย์สินหรือประโยชน์ที่เรียกเอา หรือให้เพื่อแลกเปลี่ยนเสรีภาพของผู้ถูกเอาตัวไป ผู้ถูกหน่วงเหนี่ยวหรือผู้ถูกกักขัง\n",
    "บัตรอิเล็กทรอนิกส์ หมายถึง \n",
    "(ก)เอกสารหรือวัตถุอื่นใดไม่ว่าจะมีรูปลักษณะใดที่ผู้ออกได้ออกให้แก่ผู้มีสิทธิใช้ ซึ่งจะระบุชื่อหรือไม่ก็ตาม โดยบันทึกข้อมูลหรือรหัสไว้ด้วยการประยุกต์ใช้วิธีการทางอิเล็กตรอนไฟฟ้า คลื่นแม่เหล็กไฟฟ้า \n",
    "หรือวิธีอื่นใดในลักษณะคล้ายกัน ซึ่งรวมถึงการประยุกต์ใช้วิธีการทางแสงหรือวิธีการทางแม่เหล็กให้ปรากฏความหมายด้วยตัวอักษร ตัวเลข รหัส หมายเลขบัตร หรือสัญลักษณ์อื่นใด ทั้งที่สามารถมองเห็นและมองไม่เห็นด้วยตาเปล่า\n",
    "(ข)ข้อมูล รหัส หมายเลขบัญชี หมายเลขชุดทางอิเล็กทรอนิกส์หรือเครื่องมือทางตัวเลขใด ๆ ที่ผู้ออกได้ออกให้แก่ผู้มีสิทธิใช้ โดยมิได้มีการออกเอกสารหรือวัตถุอื่นใดให้ แต่มีวิธีการใช้ในทํานองเดียวกับ (ก) หรือ\n",
    "(ค)สิ่งอื่นใดที่ใช้ประกอบกับข้อมูลอิเล็กทรอนิกส์เพื่อแสดงความสัมพันธ์ระหว่างบุคคลกับข้อมูลอิเล็กทรอนิกส์ โดยมีวัตถุประสงค์เพื่อระบุตัวบุคคลผู้เป็นเจ้าของ\n",
    "หนังสือเดินทาง = เอกสารสําคัญประจําตัวไม่ว่าจะมีรูปลักษณะใดที่รัฐบาลไทย รัฐบาลต่างประเทศ หรือองค์การระหว่างประเทศออกให้แก่บุคคลใด เพื่อใช้แสดงตนในการเดินทางระหว่างประเทศ \n",
    "และให้หมายความรวมถึงเอกสารใช้แทนหนังสือเดินทางและแบบหนังสือเดินทางที่ยังไม่ได้กรอกข้อความเกี่ยวกับผู้ถือหนังสือเดินทางด้วย\n",
    "เจ้าพนักงาน = บุคคลซึ่งกฎหมายบัญญัติว่าเป็นเจ้าพนักงานหรือได้รับแต่งตั้งตามกฎหมายให้ปฏิบัติหน้าที่ราชการ ไม่ว่าเป็นประจําหรือครั้งคราว และไม่ว่าจะได้รับค่าตอบแทนหรือไม่\n",
    "สื่อลามกอนาจารเด็ก = วัตถุหรือสิ่งที่แสดงให้รู้หรือเห็นถึงการกระทําทางเพศของเด็กหรือกับเด็กซึ่งมีอายุไม่เกินสิบแปดปี โดยรูป เรื่อง หรือลักษณะสามารถสื่อไปในทางลามกอนาจาร ไม่ว่าจะอยู่ในรูปแบบของเอกสาร ภาพเขียน ภาพพิมพ์ ภาพระบายสี สิ่งพิมพ์\n",
    "รูปภาพ ภาพโฆษณา เครื่องหมาย รูปถ่าย ภาพยนตร์ แถบบันทึกเสียง แถบบันทึกภาพ หรือรูปแบบอื่นใดในลักษณะทํานองเดียวกัน และให้หมายความรวมถึงวัตถุหรือสิ่งต่าง ๆ ข้างต้นที่จัดเก็บในระบบคอมพิวเตอร์หรือในอุปกรณ์อิเล็กทรอนิกส์อื่นที่สามารถแสดงผลให้เข้าใจความหมายได้\n",
    "\n",
    "{prompt}\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context : {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arabic_to_thai_number(input_str: str) -> str:\n",
    "    thai_digits = str.maketrans(\"0123456789\", \"๐๑๒๓๔๕๖๗๘๙\")\n",
    "    return input_str.translate(thai_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = None\n",
    "mapping_prompt = None\n",
    "with open('mapping_chunk.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for value in data:\n",
    "    print(data[value][0], data[value][1])\n",
    "\n",
    "with open('mapping_prompt.json', 'r',encoding=\"utf-8\") as file:\n",
    "    mapping_prompt = json.load(file)\n",
    "\n",
    "for value in mapping_prompt:\n",
    "    print(f\"{value} : {mapping_prompt[value]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vllm(prompt: str):\n",
    "    payload = {\n",
    "      \"model\": \"openthaigpt/openthaigpt1.5-7b-instruct\",\n",
    "      \"prompt\": prompt,\n",
    "      \"max_tokens\": 200,\n",
    "      \"temperature\": 0.7,\n",
    "      \"stream\": False\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: {response.status_code} - {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(question):\n",
    "    query_text = question\n",
    "    query_text = arabic_to_thai_number(query_text)\n",
    "    embedding_function = HuggingFaceEmbeddings(\n",
    "        model_name=\"intfloat/multilingual-e5-large\",\n",
    "        model_kwargs={\"device\": \"cpu\"},\n",
    "        encode_kwargs={\"normalize_embeddings\": True},\n",
    "    )\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "    results = db.similarity_search_with_relevance_scores(query_text, k=5)\n",
    "    print(f\"Query: {query_text}\")\n",
    "    print(f\"Results: {results}\")\n",
    "    \n",
    "    if len(results) == 0 or results[0][1] < 0.75:\n",
    "        print(f\"Unable to find matching results.\")\n",
    "        return\n",
    "\n",
    "    files = set()\n",
    "    prompt_texts = []\n",
    "    context_texts = []\n",
    "    for doc, score in results:\n",
    "        chunk_number = doc.metadata[\"chunk_number\"]\n",
    "        # print(f\"chunk_number : {chunk_number}\")\n",
    "        for value in data:\n",
    "            if chunk_number >= data[value][0] and chunk_number <= data[value][1]:\n",
    "                files.add(value)\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        context_texts.append(f\"{doc.page_content}\")\n",
    "\n",
    "    for value in files:\n",
    "        prompt_texts.append(f\"{mapping_prompt[value]}\")        \n",
    "\n",
    "    context_text = \"\".join(context_texts)\n",
    "\n",
    "    prompt_text = \"\".join(prompt_texts)\n",
    "    \n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=question, prompt=prompt_text)\n",
    "    print(f\"\\n\\n\\n\\nPrompt: {prompt}\")\n",
    "\n",
    "    response_text = query_vllm(prompt)\n",
    "    print(f\"Response Text: {response_text}\")\n",
    "\n",
    "    if isinstance(response_text, dict) and 'choices' in response_text:\n",
    "        return response_text['choices'][0]['text']\n",
    "    else:\n",
    "        return response_text  # if it's already a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "def calculate_cosine_similarity(generated_answers, reference_answers):\n",
    "    \"\"\"\n",
    "    Calculates cosine similarity between the generated and reference answers.\n",
    "\n",
    "    Args:\n",
    "        generated_answers (list[str]): Generated answers.\n",
    "        reference_answers (list[str]): Reference (gold standard) answers.\n",
    "\n",
    "    Returns:\n",
    "        float: Average cosine similarity between the answers.\n",
    "    \"\"\"\n",
    "    # Initialize the HuggingFace embedding model\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name=\"intfloat/multilingual-e5-large\",\n",
    "        model_kwargs={\"device\": \"cpu\"},\n",
    "        encode_kwargs={\"normalize_embeddings\": True},\n",
    "    )\n",
    "    \n",
    "    # Use embed_documents to generate embeddings for lists of documents\n",
    "    generated_embeddings = embedding_model.embed_documents(generated_answers)\n",
    "    reference_embeddings = embedding_model.embed_documents(reference_answers)\n",
    "    \n",
    "    # Convert to numpy arrays for compatibility\n",
    "    generated_embeddings = np.array(generated_embeddings)\n",
    "    reference_embeddings = np.array(reference_embeddings)\n",
    "    \n",
    "    # Calculate cosine similarity for each pair\n",
    "    similarities = []\n",
    "    for gen_emb, ref_emb in zip(generated_embeddings, reference_embeddings):\n",
    "        similarity = cosine_similarity([gen_emb], [ref_emb])[0][0]\n",
    "        similarities.append(similarity)\n",
    "    \n",
    "    # Return the average similarity score\n",
    "    avg_similarity = np.mean(similarities)\n",
    "    \n",
    "    return avg_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_pattern = r\"ข้อใด.*?(?=\\s*ก\\.)\"\n",
    "LABELS_FILE = 'output.csv'\n",
    "\n",
    "with open(LABELS_FILE, 'r', newline='', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    dataset = [row for row in reader]\n",
    "\n",
    "gen_answer = []\n",
    "real_answer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in dataset:\n",
    "    query = row['Question']  # Assuming the CSV has a 'Question' column\n",
    "    ans = row['Answer']\n",
    "    match = re.search(question_pattern, query, re.DOTALL)\n",
    "    if match :\n",
    "        question = match.group()\n",
    "    else :\n",
    "        question = query\n",
    "    print(question)\n",
    "    \n",
    "    response_text = response(question)\n",
    "    gen_answer.append(response_text)\n",
    "    real_answer.append(ans)\n",
    "    print(f\"Qusetion : {query}\")\n",
    "    print(f\"LLM Answer : {response_text}\")\n",
    "    print(f\"Real Answer : {ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = calculate_cosine_similarity(gen_answer, real_answer)\n",
    "print(similarity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(gen_answer))\n",
    "for i in range(len(gen_answer)):\n",
    "    print(f\"{i}\")\n",
    "    print(f\"Gen answer : {gen_answer[i]}\")\n",
    "    print(f\"Real answer : {real_answer[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response(\"การลักทรัพย์มูลค่าไม่เกิน 500 บาท มีความผิดฐานอะไร\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vllm(prompt: str):\n",
    "    payload = {\n",
    "        \"model\": \"scb10x/llama3.1-typhoon2-8b-instruct\",\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 450,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9,\n",
    "        \"frequency_penalty\": 0.4,\n",
    "        \"presence_penalty\": 0.4,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "\n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: {response.status_code} - {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read questions and answers\n",
    "with open(\"questions.txt\", \"r\", encoding=\"utf-8\") as q_file:\n",
    "    questions = [line.strip() for line in q_file.readlines()]\n",
    "\n",
    "with open(\"answers.txt\", \"r\", encoding=\"utf-8\") as a_file:\n",
    "    answers = [line.strip() for line in a_file.readlines()]\n",
    "\n",
    "# Ensure both files have the same number of lines\n",
    "if len(questions) != len(answers):\n",
    "    raise ValueError(\"Mismatch between number of questions and answers\")\n",
    "\n",
    "# Save to CSV file\n",
    "csv_filename = \"Question.csv\"\n",
    "with open(csv_filename, \"w\", encoding=\"utf-8\", newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"Question\", \"Answer\"])\n",
    "    writer.writerows(zip(questions, answers))\n",
    "\n",
    "print(\"Data successfully saved to\", csv_filename)\n",
    "\n",
    "# Load and visualize data\n",
    "df = pd.read_csv(csv_filename)\n",
    "print(df.head())  # Display first few rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
